1) What does [spark conf property] do?
A: https://spark.apache.org/docs/latest/configuration.html
2) How many partitions will be if we read 1GB file, 10 files which have 10 MB?
3) spark memory fraction
https://books.japila.pl/apache-spark-internals/configuration-properties/#sparkmemoryfraction
4) spark.sql.broadcast threshold - how size of the dataframe is calculated
https://kb.databricks.com/sql/bchashjoin-exceeds-bcjointhreshold-oom.html


5) How to investigate OOM?
6) What are the tools to get spark performance metrics/root cause of failure?
7) Spark garbage collection
